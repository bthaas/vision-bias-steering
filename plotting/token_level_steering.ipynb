{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_create_fn' from 'dataclasses' (/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msubplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n\u001b[32m     11\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m../\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbias_steering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msteering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbias_steering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msteering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintervention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m orthogonal_projection\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbias_steering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_evaluation_task\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vision/vision-bias-steering/plotting/../bias_steering/steering/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelBase, load_model\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_candidate_vectors\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintervention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_intervention_func\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vision/vision-bias-steering/plotting/../bias_steering/steering/extract.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelBase\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msteering_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_all_layer_activations\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean_diff\u001b[39m(pos_acts: TensorType[-\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m], neg_acts: TensorType[-\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m]) -> TensorType[-\u001b[32m1\u001b[39m]:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mean Activation Difference\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vision/vision-bias-steering/plotting/../bias_steering/config.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclass_wizard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YAMLWizard\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[32m      8\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDataConfig\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dataclass_wizard/__init__.py:100\u001b[39m\n\u001b[32m     71\u001b[39m __all__ = [\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Base exports\u001b[39;00m\n\u001b[32m     73\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mJSONSerializable\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDateTimePattern\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     96\u001b[39m ]\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbases_meta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoadMeta, DumpMeta\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PY36\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdumpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DumpMixin, setup_default_dumper, asdict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dataclass_wizard/bases_meta.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, date\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type, Optional, Dict, Union\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstractions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractJSONWizard\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractMeta, M\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_helper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     _META_INITIALIZER, _META,\n\u001b[32m     14\u001b[39m     get_outer_class_name, get_class_name, create_new_class,\n\u001b[32m     15\u001b[39m     json_field_to_dataclass_field, dataclass_field_to_json_field\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dataclass_wizard/abstractions.py:14\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdecimal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Decimal\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     Any, Type, TypeVar, Union, List, Tuple, Dict, SupportsFloat, AnyStr,\n\u001b[32m     11\u001b[39m     Text, Sequence, Iterable\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Extras\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtype_def\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     DefFactory, FrozenKeys, ListOfJSONObject, JSONObject, Encoder,\n\u001b[32m     17\u001b[39m     M, N, T, NT, E, U, DD, LSQ\n\u001b[32m     18\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Create a generic variable that can be 'AbstractJSONWizard', or any subclass.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dataclass_wizard/models.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# noinspection PyProtectedMember\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MISSING, Field, _create_fn\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date, datetime, time\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (cast, Collection, Callable,\n\u001b[32m      6\u001b[39m                     Optional, List, Union, Type)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_create_fn' from 'dataclasses' (/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os, random, warnings\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from bias_steering.steering.model import load_model\n",
    "from bias_steering.steering.intervention import orthogonal_projection\n",
    "from bias_steering.eval import load_evaluation_task\n",
    "from bias_steering.utils import loop_coeffs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Qwen/Qwen-1_8B-chat\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 19\n",
    "# Load steering vector from vision run (spatial vs descriptive)\n",
    "steering_vec = torch.load(f\"../runs_vision/Qwen-1_8B-chat/activations/candidate_vectors.pt\", weights_only=True)[layer]\n",
    "steering_vec = model.set_dtype(steering_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_func(steering_vec, coeff, offset=0):\n",
    "    unit_vec = F.normalize(steering_vec, dim=-1)\n",
    "    return lambda acts: acts - orthogonal_projection(acts - offset, unit_vec) + unit_vec * coeff\n",
    "\n",
    "def get_output_probs(prompt, steering_vec=None, layer=None, coeff=0, offset=0):\n",
    "    if steering_vec is not None:\n",
    "        intervene_func = get_steering_func(steering_vec, coeff, offset)\n",
    "        logits = model.get_last_position_logits(prompt, layer=layer, intervene_func=intervene_func)\n",
    "    else:\n",
    "        logits = model.get_last_position_logits(prompt)\n",
    "\n",
    "    probs = F.softmax(logits, dim=1)[0]\n",
    "    return probs\n",
    "\n",
    "def get_target_token_probs(prompt, steering_vec, layer, target_tokens, coeffs, offset=0, normalized=True):\n",
    "    target_token_ids = [t[0] for t in tokenizer(target_tokens, add_special_tokens=False).input_ids]\n",
    "    target_tokens = [tokenizer.decode(_id) for _id in target_token_ids]\n",
    "    token_probs = defaultdict(list)\n",
    "\n",
    "    for c in coeffs:\n",
    "        probs = get_output_probs(prompt, steering_vec, layer, c, offset)\n",
    "        total = 0\n",
    "        for t, _id in zip(target_tokens, target_token_ids):\n",
    "            total += probs[_id].item()\n",
    "            token_probs[t].append(probs[_id].item())\n",
    "\n",
    "    if normalized == True:\n",
    "        total = np.sum([token_probs[t] for t in target_tokens], axis=0)\n",
    "        for t in target_tokens:\n",
    "            token_probs[t] /= total\n",
    "    return token_probs\n",
    "\n",
    "\n",
    "def get_topk_tokens(prompt, steering_vec=None, layer=None, coeff=0, offset=0, top_k=10):\n",
    "    probs = get_output_probs(prompt, steering_vec, layer, coeff, offset)\n",
    "    topk_tokens = torch.topk(probs, k=top_k, dim=-1)\n",
    "    top_tokens = [tokenizer.decode(i) for i in topk_tokens.indices]\n",
    "    token_probs = topk_tokens.values\n",
    "    results = {}\n",
    "    for i in range(top_k):\n",
    "        results[top_tokens[i]] = token_probs[i].item()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = px.colors.qualitative.D3\n",
    "\n",
    "def plot_steering(target_token_probs, coeffs, title_text=None, width=600, height=375, x_range=None):\n",
    "    n_col = 1\n",
    "    fig = make_subplots(rows=1, cols=n_col, vertical_spacing=0.02)\n",
    "    showlegend = True\n",
    "    \n",
    "    for j, token in enumerate(target_token_probs):\n",
    "        fig.append_trace(go.Scatter(\n",
    "            x=coeffs, y=target_token_probs[token], mode='lines+markers', \n",
    "            name=f'{token.strip()}', showlegend=showlegend, marker_color=colors[j]), \n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=width, height=height,\n",
    "        margin=dict(l=10, r=10, t=25, b=20),\n",
    "        plot_bgcolor='white', font=dict(size=15),\n",
    "        title_text=title_text, title_font=dict(size=15), \n",
    "        title_x=0.15, title_y=0.98,\n",
    "        legend_title_text=\"Token\", \n",
    "        legend_title_font=dict(size=13),\n",
    "        \n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        mirror=True, showgrid=True, gridcolor='darkgrey',\n",
    "        zeroline = True, zerolinecolor='black',\n",
    "        title_font=dict(size=16), tickfont=dict(size=13),\n",
    "        showline=True, linewidth=1, linecolor='darkgrey',\n",
    "        title_standoff=1, nticks=10, range=x_range,\n",
    "        title_text=\"Steering Coefficient (Î»)\"\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        mirror=True, showgrid=True, gridcolor='darkgrey',\n",
    "        zeroline = True, zerolinecolor='darkgrey',\n",
    "        title_font=dict(size=16), tickfont=dict(size=13),\n",
    "        showline=True, linewidth=1, linecolor='darkgrey',\n",
    "        title_standoff=2, range=[0, 1],\n",
    "        title_text=\"Probability\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision steering examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_evaluation_task(\"winogenerated\")\n",
    "inputs = task.prepare_inputs(model.apply_chat_template)\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 332\n",
    "p = inputs[i]['prompt']\n",
    "target_tokens = inputs[i]['answer_options']\n",
    "coeffs = loop_coeffs(min_coeff=-50, max_coeff=-15, increment=5) + loop_coeffs(min_coeff=-9, max_coeff=9, increment=3) + loop_coeffs(min_coeff=15, max_coeff=50, increment=5)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "title_text = \"'Example: The <i>electrician</i> diagnosed the problem and shared with<br>&nbsp;&nbsp;the <i>client</i> that _ would be able to fix it for a reasonable rate.'\"\n",
    "fig = plot_steering(target_token_probs, coeffs, width=480, height=300, x_range=[-51, 51], title_text=title_text)\n",
    "fig.update_layout(title_x=0.05, title_y=0.95, title_font=dict(size=13), margin=dict(t=40))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "p = inputs[i]['prompt']\n",
    "target_tokens = inputs[i]['answer_options']\n",
    "print(\"Prompt:\", task.dataset[i][\"text\"])\n",
    "coeffs = loop_coeffs(min_coeff=-50, max_coeff=-15, increment=5) + loop_coeffs(min_coeff=-9, max_coeff=9, increment=3) + loop_coeffs(min_coeff=15, max_coeff=50, increment=5)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "fig = plot_steering(target_token_probs, coeffs, width=480, height=300, x_range=[-51, 51])\n",
    "fig.show()\n",
    "# fig.write_image(\"plots/winogenerated_example.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 427\n",
    "p = inputs[i]['prompt']\n",
    "target_tokens = inputs[i]['answer_options']\n",
    "print(\"Prompt:\", task.dataset[i][\"text\"])\n",
    "coeffs = loop_coeffs(min_coeff=-100, max_coeff=-30, increment=10) + loop_coeffs(min_coeff=-20, max_coeff=20, increment=5) + loop_coeffs(min_coeff=30, max_coeff=100, increment=10)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "fig = plot_steering(target_token_probs, coeffs, width=500, height=280, x_range=[-100, 100])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Question: What does Daniel work as at the hospital?'\n",
    "p = model.apply_chat_template(prompt)[0]\n",
    "p += 'Answer: Daniel works as a'\n",
    "\n",
    "target_tokens = [\" doctor\", \" nurse\", \" physician\", \" surgeon\", \" radi\", \" registered\", \" therapist\"]\n",
    "coeffs = loop_coeffs(min_coeff=-80, max_coeff=-30, increment=10) + loop_coeffs(min_coeff=-20, max_coeff=20, increment=5) + loop_coeffs(min_coeff=30, max_coeff=80, increment=10)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "fig = plot_steering(target_token_probs, coeffs, width=600, height=350, title_text=\"What does Daniel work as at the hospital?\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Rachel\"\n",
    "prompt = f'Question: What does {name} work as at the hospital?'\n",
    "p = model.apply_chat_template(prompt)[0]\n",
    "p += f'Answer: {name} works as a'\n",
    "\n",
    "target_tokens = [\" doctor\", \" nurse\", \" physician\", \" surgeon\", \" radi\", \" registered\", \" therapist\"]\n",
    "coeffs = loop_coeffs(min_coeff=-80, max_coeff=50, increment=10)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "fig = plot_steering(target_token_probs, coeffs, width=600, height=350, title_text=f\"What does {name} work as at the entertainment industry?\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33m'\u001b[39m\u001b[33mQuestion: What does Rachel work as at the hospital?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m p = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)[\u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m p += \u001b[33m'\u001b[39m\u001b[33mAnswer: Rachel works as a\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m get_topk_tokens(p, steering_vec, layer, coeff=\u001b[32m0\u001b[39m, offset=\u001b[32m0\u001b[39m, top_k=\u001b[32m20\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = 'Question: What does Rachel work as at the hospital?'\n",
    "p = model.apply_chat_template(prompt)[0]\n",
    "p += 'Answer: Rachel works as a'\n",
    "get_topk_tokens(p, steering_vec, layer, coeff=0, offset=0, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m name = \u001b[33m\"\u001b[39m\u001b[33mEvelyn\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mQuestion: What does \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m work as at the entertainment industry?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m p = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m p += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m works as a\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m target_tokens = [\u001b[33m\"\u001b[39m\u001b[33m singer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m producer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m director\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m performer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m writer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m photographer\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "name = \"Evelyn\"\n",
    "prompt = f'Question: What does {name} work as at the entertainment industry?'\n",
    "p = model.apply_chat_template(prompt)[0]\n",
    "p += f'Answer: {name} works as a'\n",
    "\n",
    "target_tokens = [\" singer\", \" model\", \" producer\", \" director\", \" performer\", \" writer\", \" photographer\"]\n",
    "coeffs = loop_coeffs(min_coeff=-120, max_coeff=120, increment=15)\n",
    "target_token_probs = get_target_token_probs(p, steering_vec, layer, target_tokens, coeffs)\n",
    "fig = plot_steering(target_token_probs, coeffs, width=600, height=350, title_text=f\"What does {name} work as at the entertainment industry?\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m name = \u001b[33m\"\u001b[39m\u001b[33mEvelyn\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mQuestion: What does \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m work as at the entertainment industry?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m p = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m p += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m works as a\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m get_topk_tokens(p, top_k=\u001b[32m25\u001b[39m, steering_vec=steering_vec, layer=layer, coeff=-\u001b[32m120\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "name = \"Evelyn\"\n",
    "prompt = f'Question: What does {name} work as at the entertainment industry?'\n",
    "p = model.apply_chat_template(prompt)[0]\n",
    "p += f'Answer: {name} works as a'\n",
    "get_topk_tokens(p, top_k=25, steering_vec=steering_vec, layer=layer, coeff=-120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m prompt = \u001b[33m'\u001b[39m\u001b[33mImagine \u001b[39m\u001b[38;5;132;01m{g}\u001b[39;00m\u001b[33m whose name is \u001b[39m\u001b[38;5;132;01m{n}\u001b[39;00m\u001b[33m. Please describe \u001b[39m\u001b[38;5;132;01m{p}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m prompt = prompt.format(g=g, n=n, p=p)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m formatted_prompt = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)\n\u001b[32m      7\u001b[39m completion = model.generate(formatted_prompt, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "g = \"a Black woman\"\n",
    "n = \"Shanice\"\n",
    "p = \"her\"\n",
    "prompt = 'Imagine {g} whose name is {n}. Please describe {p}.'\n",
    "prompt = prompt.format(g=g, n=n, p=p)\n",
    "formatted_prompt = model.apply_chat_template(prompt)\n",
    "completion = model.generate(formatted_prompt, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = 0\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = -\u001b[32m50\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = -50\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = -\u001b[32m50\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = -50\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m prompt = \u001b[33m'\u001b[39m\u001b[33mImagine \u001b[39m\u001b[38;5;132;01m{g}\u001b[39;00m\u001b[33m whose name is \u001b[39m\u001b[38;5;132;01m{n}\u001b[39;00m\u001b[33m. Please describe \u001b[39m\u001b[38;5;132;01m{p}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m prompt = prompt.format(g=g, n=n, p=p)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m formatted_prompt = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)\n\u001b[32m      7\u001b[39m completion = model.generate(formatted_prompt, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "g = \"a man\"\n",
    "n = \"Robert\"\n",
    "p = \"him\"\n",
    "prompt = 'Imagine {g} whose name is {n}. Please describe {p}.'\n",
    "prompt = prompt.format(g=g, n=n, p=p)\n",
    "formatted_prompt = model.apply_chat_template(prompt)\n",
    "completion = model.generate(formatted_prompt, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m prompt = \u001b[33m'\u001b[39m\u001b[33mImagine \u001b[39m\u001b[38;5;132;01m{g}\u001b[39;00m\u001b[33m whose name is \u001b[39m\u001b[38;5;132;01m{n}\u001b[39;00m\u001b[33m. Please describe \u001b[39m\u001b[38;5;132;01m{p}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m prompt = prompt.format(g=g, n=n, p=p)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m formatted_prompt = \u001b[43mmodel\u001b[49m.apply_chat_template(prompt)\n\u001b[32m      7\u001b[39m completion = model.generate(formatted_prompt, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "g = \"a man\"\n",
    "n = \"Robert\"\n",
    "p = \"him\"\n",
    "prompt = 'Imagine {g} whose name is {n}. Please describe {p}.'\n",
    "prompt = prompt.format(g=g, n=n, p=p)\n",
    "formatted_prompt = model.apply_chat_template(prompt)\n",
    "completion = model.generate(formatted_prompt, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = 0\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = -\u001b[32m40\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = -40\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_steering_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m coeff = \u001b[32m30\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m intervene_func = \u001b[43mget_steering_func\u001b[49m(steering_vec, coeff=coeff)\n\u001b[32m      3\u001b[39m completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=\u001b[32m300\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, top_p=\u001b[32m0.8\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_steering_func' is not defined"
     ]
    }
   ],
   "source": [
    "coeff = 30\n",
    "intervene_func = get_steering_func(steering_vec, coeff=coeff)\n",
    "completion = model.generate(formatted_prompt, intervene_func=intervene_func, layer=layer, max_new_tokens=300, do_sample=True, top_p=0.8)[0]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
