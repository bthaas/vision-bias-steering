{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from bias_steering.steering import load_model, get_intervention_func, get_target_token_ids\n",
    "from bias_steering.utils import loop_coeffs\n",
    "from bias_steering.data.load_dataset import load_target_words\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG: pick your model ---\n",
    "MODEL_NAME = 'gpt2'  # or 'Qwen/Qwen-1_8B-chat'\n",
    "MODEL_ALIAS = 'gpt2'  # or 'Qwen-1_8B-chat'\n",
    "LAYER = 5  # best layer for gpt2; use 11 for Qwen\n",
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "artifact_dir = Path(f'../runs_vision/{MODEL_ALIAS}')\n",
    "candidate_vectors = torch.load(artifact_dir / 'activations/candidate_vectors.pt')\n",
    "steering_vec = model.set_dtype(candidate_vectors[LAYER])\n",
    "print(f'Loaded {MODEL_NAME}, steering vec shape: {steering_vec.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick specific spatial and descriptive tokens to track\n",
    "spatial_tokens = [' left', ' right', ' behind', ' near', ' above', ' below', ' next']\n",
    "descriptive_tokens = [' red', ' blue', ' large', ' small', ' round', ' bright', ' dark']\n",
    "\n",
    "all_tokens = spatial_tokens + descriptive_tokens\n",
    "token_ids = [model.tokenizer.encode(t, add_special_tokens=False)[0] for t in all_tokens]\n",
    "token_labels = [t.strip() for t in all_tokens]\n",
    "print('Tracking tokens:', token_labels)\n",
    "print('Token IDs:', token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - a COCO-style caption that could go either way\n",
    "caption = 'A cat sitting on a mat in a room with furniture.'\n",
    "prompt = f'Continue describing this scene:\\n{caption}'\n",
    "p = model.apply_chat_template([prompt])[0]\n",
    "p += 'The scene is'\n",
    "print(f'Full prompt:\\n{p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep coefficients and record per-token probabilities\n",
    "coeffs = list(loop_coeffs(min_coeff=-80, max_coeff=80, increment=10))\n",
    "token_probs = {label: [] for label in token_labels}\n",
    "\n",
    "for coeff in coeffs:\n",
    "    intervene_func = get_intervention_func(steering_vec, method='constant', coeff=coeff)\n",
    "    logits = model.get_logits([p], layer=LAYER, intervene_func=intervene_func)\n",
    "    probs = F.softmax(logits[0, -1, :], dim=-1)\n",
    "    for tid, label in zip(token_ids, token_labels):\n",
    "        token_probs[label].append(probs[tid].item())\n",
    "\n",
    "print(f'Swept {len(coeffs)} coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it\n",
    "colors_spatial = px.colors.qualitative.Set1[:len(spatial_tokens)]  # warm colors\n",
    "colors_desc = px.colors.qualitative.Set2[:len(descriptive_tokens)]  # cool colors\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, label in enumerate([t.strip() for t in spatial_tokens]):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=coeffs, y=token_probs[label],\n",
    "        mode='lines+markers', name=f'{label} (spatial)',\n",
    "        marker_color=colors_spatial[i], line=dict(width=2),\n",
    "    ))\n",
    "for i, label in enumerate([t.strip() for t in descriptive_tokens]):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=coeffs, y=token_probs[label],\n",
    "        mode='lines+markers', name=f'{label} (desc)',\n",
    "        marker_color=colors_desc[i], line=dict(width=2, dash='dash'),\n",
    "    ))\n",
    "\n",
    "fig.add_vline(x=0, line_dash='solid', line_color='black', line_width=1)\n",
    "fig.update_layout(\n",
    "    title=f'Token Probabilities vs Steering Coefficient ({MODEL_NAME})',\n",
    "    title_font=dict(size=16), title_x=0.5,\n",
    "    width=750, height=450, plot_bgcolor='white',\n",
    "    legend=dict(title='Token', font=dict(size=12)),\n",
    ")\n",
    "fig.update_xaxes(title='Steering Coefficient (\\u03bb)', showgrid=True, gridcolor='lightgrey')\n",
    "fig.update_yaxes(title='Probability', showgrid=True, gridcolor='lightgrey', range=[0, None])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple prompt examples: inspect top next-token predictions\n",
    "example_captions = [\n",
    "    'A red bus parked beside a curb near a crosswalk.',\n",
    "    'Two dogs playing in a grassy field under the sky.',\n",
    "    'A kitchen table with plates, cups, and fruit on top.',\n",
    "    'A person standing to the left of a parked bicycle.',\n",
    "    'A bright yellow kite flying above a grassy park.',\n",
    "    'Three elephants near the water with trees behind them.',\n",
    "    'A black and white cat sleeping on a blue sofa.',\n",
    "    'A stop sign at the corner in front of a brick building.',\n",
    "    'A bowl of oranges and apples on a wooden table.',\n",
    "    'A train passing under a bridge next to a road.'\n",
    "]\n",
    "\n",
    "# Multiple prompt examples: inspect top next-token predictions\n",
    "\n",
    "def show_next_token_examples(captions, coeff=0.0, top_k=8):\n",
    "    intervene_func = get_intervention_func(steering_vec, method='constant', coeff=coeff)\n",
    "    for i, caption in enumerate(captions, start=1):\n",
    "        prompt = f'Continue describing this scene:\\n{caption}'\n",
    "        full_prompt = model.apply_chat_template([prompt])[0] + 'The scene is'\n",
    "        logits = model.get_logits([full_prompt], layer=LAYER, intervene_func=intervene_func)\n",
    "        probs = F.softmax(logits[0, -1, :], dim=-1)\n",
    "        top_probs, top_ids = torch.topk(probs, k=top_k)\n",
    "\n",
    "        print(f'\\nExample {i} | coeff={coeff}')\n",
    "        print(f'Caption: {caption}')\n",
    "        for rank, (tid, pval) in enumerate(zip(top_ids.tolist(), top_probs.tolist()), start=1):\n",
    "            tok = model.tokenizer.decode([tid]).replace('\\n', '\\\\n')\n",
    "            print(f'  {rank:>2}. token={tok!r:>14} prob={pval:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run examples at baseline and with steering\n",
    "show_next_token_examples(example_captions, coeff=0.0, top_k=8)\n",
    "show_next_token_examples(example_captions, coeff=-200.0, top_k=8)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}